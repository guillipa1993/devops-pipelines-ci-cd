name: "Analyze and Create JIRA Tickets"

on:
  workflow_call:
    secrets:
      AZURE_STORAGE_ACCOUNT_NAME:
        description: "Azure Storage Account Name"
        required: true
      AZURE_STORAGE_ACCOUNT_KEY:
        description: "Azure Storage Account Key"
        required: true
      OPENAI_API_KEY:
        description: "OpenAI API Key"
        required: true
      JIRA_CLOUD_API_TOKEN:
        description: "Jira Cloud API Token"
        required: true
      JIRA_CLOUD_USERNAME:
        description: "Jira Cloud Username"
        required: true
    inputs:
      project-name:
        description: "The name of the GitHub repository"
        required: true
        type: string
      run-id:
        description: "The ID of the current GitHub run"
        required: true
        type: string
      report-language:
        description: "Language for the summary report (default: English)"
        required: false
        type: string
        default: "English"
      log-type:
        description: "Type of logs to analyze (e.g., failure, success)"
        required: true
        type: string
      repo:
        description: "The name of the GitHub repository (owner/repo)"
        required: true
        type: string
      jira-project-key:
        description: "Reference to the Jira Project"
        required: true
        type: string
      jira-url:
        description: "URL of the Jira Cloud instance"
        required: true
        type: string

jobs:
  analyze-and-create:
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4

      - name: Install dependencies
        run: |
          set -e
          python -m pip install --upgrade pip
          pip install jira requests openai
          python -c "import openai; print('OpenAI library installed successfully')"
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Download your unified script
        run: |
          set -e
          echo "Cloning devops-pipelines-ci-cd in branch Add-copilot-and-jira..."
          git clone --depth=1 --branch Add-copilot-and-jira https://github.com/guillipa1993/devops-pipelines-ci-cd.git

          if [ ! -d "devops-pipelines-ci-cd/scripts" ]; then
            echo "ERROR: Expected directory devops-pipelines-ci-cd/scripts not found." >&2
            exit 1
          fi

          echo "List of files in devops-pipelines-ci-cd/scripts/:"
          ls -R devops-pipelines-ci-cd/scripts/

          mkdir -p scripts
          cp devops-pipelines-ci-cd/scripts/unified_analyze_and_create.py scripts/

          if [ ! -f "scripts/unified_analyze_and_create.py" ]; then
            echo "ERROR: No unified script found in devops-pipelines-ci-cd/scripts/." >&2
            exit 1
          fi
          echo "Found unified_analyze_and_create.py script."

      - name: Download All Logs Matching Pattern
        run: |
          set -e
          REPO_NAME="${{ inputs.project-name }}"
          RUN_ID="${{ inputs.run-id }}"
          LOG_PREFIX="${REPO_NAME}-${RUN_ID}-"

          mkdir -p "$GITHUB_WORKSPACE/logs"

          az storage blob list \
              --account-name "${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" \
              --account-key "${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }}" \
              --container-name logs \
              --query "[].{name:name}" -o tsv | grep "${LOG_PREFIX}" | grep -E '\.(log|sarif)$' | grep -v '^$' > matching_blobs.txt || true

          if [ ! -s matching_blobs.txt ]; then
              echo "No .log or .sarif files found for pattern: ${LOG_PREFIX}*.{log,sarif}"
              exit 0
          fi

          while IFS= read -r blob_name || [ -n "$blob_name" ]; do
            echo "Downloading $blob_name"

            download_path="$GITHUB_WORKSPACE/logs/$blob_name"
            mkdir -p "$(dirname "$download_path")"

            az storage blob download \
              --account-name "${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" \
              --account-key "${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }}" \
              --container-name logs \
              --name "$blob_name" \
              --file "$download_path"
          done < matching_blobs.txt

          echo "Logs downloaded:"
          ls -la "$GITHUB_WORKSPACE/logs"
        env:
          AZURE_STORAGE_ACCOUNT_NAME: ${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}
          AZURE_STORAGE_ACCOUNT_KEY: ${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }}

      - name: Run unified script to Analyze + Create JIRA Tickets
        run: |
          set -e
          python scripts/unified_analyze_and_create.py \
            --jira-url "${{ inputs.jira-url }}" \
            --jira-project-key "${{ inputs.jira-project-key }}" \
            --log-dir "$GITHUB_WORKSPACE/logs" \
            --log-type "${{ inputs.log-type }}" \
            --report-language "${{ inputs.report-language }}" \
            --project-name "${{ inputs.project-name }}" \
            --run-id "${{ inputs.run-id }}" \
            --repo "${{ inputs.repo }}"
        env:
          JIRA_API_TOKEN: ${{ secrets.JIRA_CLOUD_API_TOKEN }}
          JIRA_USER_EMAIL: ${{ secrets.JIRA_CLOUD_USERNAME }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
